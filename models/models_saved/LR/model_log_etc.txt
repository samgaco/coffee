

start_time=time.time()

pipe = make_pipeline(TfidfVectorizer(
                                    stop_words='english',
                                    strip_accents='unicode',
                                    token_pattern=r'\w{1,}', #accept tokens that have 1 or more characters
                                    analyzer='word',
                                    ngram_range=(1, 1),
                                    min_df=5),
                     OneVsRestClassifier(LogisticRegression()))
param_grid = {'tfidfvectorizer__max_features': [10000, 30000],
              'onevsrestclassifier__estimator__solver': ['liblinear', 'sag'],
             }
grid = GridSearchCV(pipe, param_grid, cv=3, scoring='roc_auc')

grid3 = grid.fit(x_train, y_train)

end_time=time.time()
print("total time",end_time-start_time)



# Save classifier to a file

save_classifier = open("Tfidf_LogR_3.pickle", 'wb') #wb= write in bytes.
pickle.dump(grid3, save_classifier) #use pickle to dump the grid3 we trained, as 'Tfidf_LogR.pickle' in wb format
save_classifier.close()

# Retrieve the saved file and uplaod it to an object

vec = open("Tfidf_LogR_3.pickle", 'rb') # rb= read in bytes
grid3 = pickle.load(vec)
vec.close()




vectorizer = grid3.best_estimator_.named_steps["tfidfvectorizer"]
# transform the training dataset:
X_test_set = vectorizer.transform(x_test)


# find maximum value for each of the features over dataset:
max_value = X_test_set.max(axis=0).toarray().ravel()
sorted_by_tfidf = max_value.argsort()

# get feature names
feature_names = np.array(vectorizer.get_feature_names())

print("Features with lowest tfidf:\n{}".format(
      feature_names[sorted_by_tfidf[:20]]))

print("\nFeatures with highest tfidf: \n{}".format(
      feature_names[sorted_by_tfidf[-20:]]))

sorted_by_idf = np.argsort(vectorizer.idf_)
print("Features with lowest idf:\n{}".format(
       feature_names[sorted_by_idf[:100]]))



print("First: \n{}".format(confusion_matrix(y_test['one'], predicted_y_test[:,0])))
print("\nsecond: \n{}".format(confusion_matrix(y_test['two'], predicted_y_test[:,1])))
print("\nthird: \n{}".format(confusion_matrix(y_test['three'], predicted_y_test[:,2])))
print("\nfourth: \n{}".format(confusion_matrix(y_test['four'], predicted_y_test[:,3])))
print("\nfifth: \n{}".format(confusion_matrix(y_test['five'], predicted_y_test[:,4])))

print("\nFirst: \n{}".format(classification_report(y_test['one'], predicted_y_test[:,0])))
print("\nSecond: \n{}".format(classification_report(y_test['two'], predicted_y_test[:,1])))
print("\nThird: \n{}".format(classification_report(y_test['three'], predicted_y_test[:,2])))
print("\nFourth: \n{}".format(classification_report(y_test['four'], predicted_y_test[:,3])))
print("\nFifth: \n{}".format(classification_report(y_test['five'], predicted_y_test[:,4])))

print(y_train.columns)
print("\n-Columns are ordered as above, which is why coef_[0] refers to the first class"
      " and coef_[5] refers to identity fifth class.")
print("-The blue bars refer to the label (first class) and the red refer to not first class")

for i in range(5):
    mglearn.tools.visualize_coefficients(
         grid3.best_estimator_.named_steps["onevsrestclassifier"].coef_[i],
          feature_names, n_top_features=40)





